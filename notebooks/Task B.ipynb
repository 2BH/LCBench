{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B: Meta-Learning Perfomance Prediction\n",
    "\n",
    "In this task, you will use learning curves on multiple openml dataset to train a performance predictor that performs well even for unseen datasets. You should only use the first 10 epochs of the learning curves in your predictions. You are provided with learning curves and config parameters for six datasets. The datasets are split into training datasets and meta datasets and you should only train on the training datasets.\n",
    "\n",
    "Note: This notebook is meant to show how to use the API. You can choose which data you use for your predictions and should create your own dataloading and splits, however your are free to use code from here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifications:\n",
    "\n",
    "* Data: six_datasets_lw.json\n",
    "* Number of datasets: 6\n",
    "* Training datasets: higgs, vehicle, adult, volkert\n",
    "* Meta datasets: Fashion-MNIST, jasmine\n",
    "* Number of configurations: 2000\n",
    "* Number of epochs seen when predicting: 10\n",
    "* Available data: Learning curves, architecture parameters and hyperparameters \n",
    "* Target: Final validation accuracy\n",
    "* Evaluation metric: MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and splitting data\n",
    "\n",
    "Note: There are 51 steps logged, 50 epochs plus the 0th epoch, prior to any weight updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd ..\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from api import Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading data...\n",
      "==> No cached data found or cache set to False.\n",
      "==> Reading json data...\n",
      "==> Done.\n"
     ]
    }
   ],
   "source": [
    "bench_dir = \"cached/six_datasets_lw.json\"\n",
    "bench = Benchmark(bench_dir, cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fashion-MNIST', 'adult', 'higgs', 'jasmine', 'vehicle', 'volkert']\n"
     ]
    }
   ],
   "source": [
    "# Dataset split\n",
    "dataset_names = bench.get_dataset_names()\n",
    "print(dataset_names)\n",
    "\n",
    "train_datasets = ['adult', 'higgs', 'vehicle', 'volkert']\n",
    "test_datasets = ['Fashion-MNIST', 'jasmine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (5600, 51)\n",
      "X_test: (4000, 11)\n",
      "X_val: (2400, 11)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "def read_data(datasets):\n",
    "    n_configs = bench.get_number_of_configs(datasets[0])\n",
    "    data = [bench.query(dataset_name=d, tag=\"Train/val_accuracy\", config_id=ind) for d in datasets for ind in range(n_configs)]\n",
    "    configs = [bench.query(dataset_name=d, tag=\"config\", config_id=ind) for d in datasets for ind in range(n_configs)]\n",
    "    dataset_names = [d for d in datasets for ind in range(n_configs)]\n",
    "    \n",
    "    X = np.array([curve[:-1] for curve in data])\n",
    "    y = np.array([curve[-1] for curve in data])\n",
    "    return X, y, np.array(configs), np.array(dataset_names)\n",
    "\n",
    "class TrainValSplitter():\n",
    "    \"\"\"Splits 30 % data as a validation split.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_names):\n",
    "        self.ind_train, self.ind_val = train_test_split(np.arange(len(X)), test_size=0.3, stratify=dataset_names)\n",
    "        \n",
    "    def split(self, a):\n",
    "        return a[self.ind_train], a[self.ind_val]\n",
    "    \n",
    "    def cut(self, a, outlength=11):\n",
    "        return np.array([curve[:outlength] for curve in a])\n",
    "\n",
    "X, y, configs, dataset_names = read_data(train_datasets)\n",
    "X_test, y_test, configs_test, dataset_names_test = read_data(test_datasets)\n",
    "\n",
    "tv_splitter = TrainValSplitter(dataset_names=dataset_names)\n",
    "\n",
    "X_train, X_val = tv_splitter.split(X)\n",
    "y_train, y_val = tv_splitter.split(y)\n",
    "configs_train, configs_val = tv_splitter.split(configs)\n",
    "dataset_names_train, dataset_names_val = tv_splitter.split(configs)\n",
    "\n",
    "X_test, X_val = tv_splitter.cut(X_test), tv_splitter.cut(X_val)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"X_val:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLearningCurvePredictor():\n",
    "    \"\"\"A learning curve predictor that predicts the last observed epoch as final performance\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for curve in X:\n",
    "            predictions.append(curve[-1])\n",
    "        return predictions\n",
    "    \n",
    "def score(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.580016418521055\n"
     ]
    }
   ],
   "source": [
    "predictor = SimpleLearningCurvePredictor()\n",
    "predictor.fit(X_train, y_train)\n",
    "preds = predictor.predict(X_val)\n",
    "mse = score(y_val, preds)\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
