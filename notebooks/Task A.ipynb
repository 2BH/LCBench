{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task A: Creating a Performance Predictor\n",
    "\n",
    "In this task, you will use training data from 2000 configurations on a single openml dataset to train a performance predictor. You should split the data you use into into train, test and validation set and only use the first 10 epochs of the learning curves in your predictions. You are provided with the full benchmark logs for Fashion-MNIST, that is learning curves, config parameters and gradient statistics, and you can use them freely.\n",
    "\n",
    "Note: This notebook is meant to show how to use the API. You can choose which data you use for your predictions and should create your own dataloading and splits, however your are free to use code from here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifications:\n",
    "\n",
    "* Data: fashion_mnist.json\n",
    "* Number of datasets: 1\n",
    "* Number of configurations: 2000\n",
    "* Number of epochs seed during prediction: 10\n",
    "* Available data: Learning curves, architecture parameters and hyperparameters, gradient statistics \n",
    "* Target: Final validation accuracy\n",
    "* Evaluation metric: MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and splitting data\n",
    "\n",
    "Note: There are 51 steps logged, 50 epochs plus the 0th epoch, prior to any weight updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd ..\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from api import Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading data...\n",
      "==> No cached data found or cache set to False.\n",
      "==> Reading json data...\n",
      "==> Done.\n"
     ]
    }
   ],
   "source": [
    "bench_dir = \"cached/fashion_mnist.json\"\n",
    "bench = Benchmark(bench_dir, cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "dataset_names = bench.get_dataset_names()\n",
    "n_configs = bench.get_number_of_configs(dataset_names[0])\n",
    "\n",
    "data = [bench.query(dataset_name=dn, tag=\"Train/val_accuracy\", config_id=ind) for dn in dataset_names for ind in range(n_configs)]\n",
    "configs = [bench.query(dataset_name=dn, tag=\"config\", config_id=ind) for dn in dataset_names for ind in range(n_configs)]\n",
    "\n",
    "X = np.array([curve[:-1] for curve in data])\n",
    "y = np.array([curve[-1] for curve in data])\n",
    "configs = np.array(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (980, 51)\n",
      "X_test: (600, 11)\n",
      "X_val: (420, 11)\n"
     ]
    }
   ],
   "source": [
    "# Create train test and validation split\n",
    "class TrainTestValSplitter():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.ind_train, self.ind_test = train_test_split(np.arange(len(X)), test_size=0.3)\n",
    "        self.subind_train, self.subind_val = train_test_split(np.arange(len(self.ind_train)), test_size=0.3)\n",
    "        \n",
    "    def split(self, a):\n",
    "        return a[self.ind_train][self.subind_train], a[self.ind_test], a[self.ind_train][self.subind_val]\n",
    "    \n",
    "    def cut(self, a, outlength=11):\n",
    "        return np.array([curve[:outlength] for curve in a])\n",
    "    \n",
    "ttv_splitter = TrainTestValSplitter()\n",
    "\n",
    "X_train, X_test, X_val = ttv_splitter.split(X)\n",
    "y_train, y_test, y_val = ttv_splitter.split(y)\n",
    "configs_train, configs_test, configs_val = ttv_splitter.split(configs)\n",
    "\n",
    "X_test, X_val = ttv_splitter.cut(X_test), ttv_splitter.cut(X_val)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"X_val:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLearningCurvePredictor():\n",
    "    \"\"\"A learning curve predictor that predicts the last observed epoch as final performance\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for curve in X:\n",
    "            predictions.append(curve[-1])\n",
    "        return predictions\n",
    "    \n",
    "def score(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.580107630975185\n"
     ]
    }
   ],
   "source": [
    "predictor = SimpleLearningCurvePredictor()\n",
    "preds = predictor.predict(X_val)\n",
    "mse = score(y_val, preds)\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
